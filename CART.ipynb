{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02daa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d733bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f951230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version : 3.8.10\n",
      "np version :  1.24.3\n",
      "pd version :  2.0.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"python version : {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",)\n",
    "\n",
    "print(\"np version : \", np.__version__)\n",
    "print(\"pd version : \",pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2961d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cfe37-e8a0-4934-abe0-5c419392331c",
   "metadata": {},
   "source": [
    "Goal: predict article for each customer for next 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce39de9",
   "metadata": {},
   "source": [
    "dataset : https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df = pd.read_csv(\"data/h&m/transactions_train.csv\")\n",
    "user_df = pd.read_parquet(\"data/h&m/customers.parquet\")\n",
    "item_df = pd.read_parquet(\"data/h&m/articles.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22f99e-4425-4b8d-9ac4-045cb034c86b",
   "metadata": {},
   "source": [
    "# configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d058d8e2-34fd-4913-b1eb-33cbf2d33e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 't_dat'\n",
    "user_col = 'customer_id'\n",
    "item_col = 'product_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2856f-361f-4f5a-b159-d85ac124f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df[date_col] = pd.to_datetime(interaction_df[date_col], format='%Y-%m-%d')\n",
    "print(\"shape : \", interaction_df.shape)\n",
    "interaction_df[['customer_id', 'article_id', 'sales_channel_id']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fc759-b486-49bc-b27c-f10f1e9666e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d696b-2428-4e0f-a959-edaa78a43111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_df.shape)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de0ab1-cca9-4423-bb9f-79aea96ba775",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(item_df.shape)\n",
    "item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de51a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of items have same product_code but different product name. BUT good things is all other columns seems to be same.\n",
    "# We will ignore them for now and just use latest product name for item_cd2nm_map\n",
    "item_df.groupby(['product_code'])[['prod_name']].nunique().sort_values(\"prod_name\", ascending=False).iloc[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d787889",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cd2nm_map = dict(zip(item_df[item_col],  item_df[\"prod_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_cd2nm_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9948a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/h&m/item_cd2nm_map.pickle', 'wb') as f:\n",
    "    pickle.dump(item_cd2nm_map, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20fc42-b142-4b95-a80b-c177515635a5",
   "metadata": {},
   "source": [
    "# Item2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbad277",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadda592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply add prdt_cd\n",
    "interaction_df = interaction_df.merge(item_df[['article_id', item_col]], how='left', on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85162aa1-fd27-4fb8-9804-a4493b0305ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = interaction_df.loc[interaction_df['t_dat'] < '2020-01-01'].copy()\n",
    "test_df = interaction_df.loc[interaction_df['t_dat'] >= '2020-01-01'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"trainset date range : {train_df[date_col].min()} ~ {train_df[date_col].max()}\")\n",
    "print(f\"testset date range : {test_df[date_col].min()} ~ {test_df[date_col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd11cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765be1b-780b-4649-9ea0-0dac25b1a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for each user on all train dataset.\n",
    "user_seq = train_df.groupby(user_col)[item_col].apply(list)\n",
    "user_seq_df = pd.DataFrame(user_seq).rename(columns={item_col:\"seq_list\"})\n",
    "tr_seq_df = train_df.drop_duplicates(user_col, keep='first')\n",
    "tr_seq_df = tr_seq_df.merge(user_seq_df, on=user_col)\n",
    "tr_seq_df['n_seq'] = tr_seq_df['seq_list'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690d039-8f0a-44ef-b03f-c876bd518669",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_seq_df[['n_seq']].hist(bins=100, figsize=(4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ceb1c-0eb2-49a3-ad06-0295ec95d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sequences = tr_seq_df['seq_list'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fb2d0-1392-4724-9ab7-33d110579071",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tr_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564eaafb-5345-43b1-8225-95e2b5b07145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(vector_size = 100, #\n",
    "                 workers = 4, # s\n",
    "                 sg = 1, # 1 = Skip-gram, else = CBOW\n",
    "                 hs = 0, # Hierachical softmax = 1, else Negative sampling\n",
    "                 negative = 3, \n",
    "                 window = 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d459c86-707f-4785-a500-06ce17505776",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_time = time.perf_counter()\n",
    "model.build_vocab(tr_sequences, progress_per=10_000)\n",
    "model.train(tr_sequences, total_examples=model.corpus_count,\n",
    "           epochs=10)\n",
    "print(time.perf_counter() - st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd595193-89e9-4f01-b499-cd9b87d461e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Store trained word vectors in `KeyedVectors` instance\n",
    "No need to save model (containing curr state) if no additional training is required.\n",
    "\n",
    "Keeping only word embedding space makes it more memory efficient\n",
    "\"\"\"\n",
    "item_vectors = model.wv\n",
    "item_vectors[663713001] # get item_id's item vector\n",
    "\n",
    "\n",
    "item_vectors.save(\"trained_model/item2vec_emb_space.wordvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb4642",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2892a4c-de4b-48ff-81a7-ccfa3b111996",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_item_embeddings = KeyedVectors.load(\"trained_model/item2vec_emb_space.wordvectors\"\n",
    "                           , mmap='r' # Load with memory-mapping which is read-only, shared across processes thus faster.\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94901f-5a0f-4336-9535-0c3a10808a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0,\n",
    "                              n_components=2, random_state=42).fit_transform(X)\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.scatter(cluster_embedding[:, 0], cluster_embedding[:, 1], s=3, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e424f8-792a-4da2-9952-e239dc7fd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_seq = test_df.groupby(user_col)[item_col].apply(list)\n",
    "user_seq_df = pd.DataFrame(user_seq).rename(columns={item_col:\"seq_list\"})\n",
    "test_seq_df = test_df.drop_duplicates(user_col, keep='first')\n",
    "test_seq_df = test_seq_df.merge(user_seq_df, on=user_col)\n",
    "test_seq_df['n_seq'] = test_seq_df['seq_list'].str.len()\n",
    "\n",
    "# # filter : n_seq > 3 to use both: item2item, seq(user)2item  \n",
    "# test_seq_df = test_seq_df.loc[test_seq_df['n_seq'] >= 3].copy()\n",
    "test_seq_df['true_y'] = test_seq_df['seq_list'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dafed016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_seq_df.to_parquet(\"data/h&m/test_seq_df.parquet\")\n",
    "test_seq_df = pd.read_parquet(\"data/h&m/test_seq_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ad5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_df.groupby(['n_seq']).count().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efda8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_seq_df.shape)\n",
    "test_seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e65cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cart import get_recc, get_user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397e5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 10 # so we can recomend at least 10 items with 1 item vector to represent that user.\n",
    "\n",
    "test_seq_df = test_seq_df.loc[test_seq_df['n_seq'] > min_n_seq].copy()\n",
    "test_seq_df['input_items'] = test_seq_df['seq_list'].apply(lambda row: row[:-topk])\n",
    "test_seq_df['target_items'] = test_seq_df['seq_list'].apply(lambda row: row[-topk:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9599379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recc on 315563users, 10 recc each took : 45.95136070000001s\n"
     ]
    }
   ],
   "source": [
    "st_time = time.perf_counter()\n",
    "rec_result_dfs = []\n",
    "column_order = [user_col, item_col, 'item_nm', 'score', 'rank']\n",
    "topk = 10\n",
    "i = 0\n",
    "for row in test_seq_df.iloc[:1000].itertuples():\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"on {i}th user\")\n",
    "    user_id = getattr(row, user_col)\n",
    "    input_item_seq = getattr(row, 'input_items')\n",
    "    \n",
    "    # 1) Combine item vectors to create user vector\n",
    "    user_vector, cold_items = get_user_vector(learned_item_embeddings, input_item_seq, method='sum')\n",
    "    \n",
    "    # all cold-items, cannot make rec\n",
    "    if not np.any(user_vector):\n",
    "        continue\n",
    "\n",
    "    # 2)Get rec for each user\n",
    "    # hm... How should I leverage arithmetics ?\n",
    "    rec_df = get_recc(learned_item_embeddings, item_col, user_vector, negatives=None, topn=topk)\n",
    "    rec_df[user_col] = user_id\n",
    "    rec_df['n_cold_items'] = len(cold_items)\n",
    "    rec_result_dfs.append(rec_df[column_order])\n",
    "\n",
    "print(f\"recc on {len(test_seq_df)}users, {topk} recc each took : {time.perf_counter() - st_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f73d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_result_df = pd.concat(rec_result_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e4bff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rec_result_df.groupby(user_col)[item_col].apply(lambda x: list(x))).rename(columns={item_col:\"topk_rec\"})\n",
    "perm_metric_df = test_seq_df.merge(df, left_on='customer_id', right_index=True\n",
    "                                   , how='inner'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1863ed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t_dat               0\n",
       "customer_id         0\n",
       "article_id          0\n",
       "price               0\n",
       "sales_channel_id    0\n",
       "product_code        0\n",
       "seq_list            0\n",
       "n_seq               0\n",
       "true_y              0\n",
       "input_items         0\n",
       "target_items        0\n",
       "topk_rec            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(perm_metric_df.shape)\n",
    "perm_metric_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b7208eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_at_k(topk_recs, target_items):\n",
    "    rec_items_set = set(topk_recs[:topk])\n",
    "    target_items_set = set(target_items)\n",
    "    \n",
    "    return len(rec_items_set&target_items_set) / topk\n",
    "\n",
    "def recall_at_k(topk_recs, target_items):\n",
    "    rec_items_set = set(topk_recs[:topk])\n",
    "    target_items_set = set(target_items)\n",
    "    denom = n_of_relevant_items # ...? But in item2vec aren't all items considered relevant?\n",
    "    \n",
    "    return len(rec_items_set&target_items_set) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2d33d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_metric_df[f'prec@{topk}']=perm_metric_df.apply(lambda row: prec_at_k(row.topk_rec, row.target_items), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f647c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec@10 =  0.0253\n"
     ]
    }
   ],
   "source": [
    "print(f\"prec@{topk} = \", np.sum(perm_metric_df['prec@10']) / len(perm_metric_df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7722e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee89886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_result_df = pd.concat(rec_result_dfs)\n",
    "rec_result_df.to_parquet(\"data/h%m/rec_result_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    " # ??? How to measure other rec/classification metrics?, is hit@K only possible one? \n",
    "     # if not is it fair to compare with deepfm metrics?\n",
    "for csno in csno_lst:\n",
    "    csno_df = rec_result_df.loc[rec_result_df['csno'] == csno].copy()\n",
    "    rec_set = set(csno_df.iloc[:topk]['recommended_item_id'])\n",
    "    target = {csno_df['target_item_id'][0]}\n",
    "    # hit@K\n",
    "    if len(rec_set.intersection(target)) > 0:\n",
    "        users_hit.append(1)\n",
    "    else:\n",
    "        users_hit.append(0)\n",
    "\n",
    "hit_at_k = np.sum(users_hit) / len(csno_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e19367",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_df.iloc[0]['seq_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_df.iloc[0]['item2item_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeed1cc",
   "metadata": {},
   "source": [
    "### Seq2Vec\n",
    "\n",
    "- combine sequence of item vectors to generate user vector, find similar items in trained item embedding for recommendation.\n",
    "- Only difference between Seq2Vec and Item2Vec is during inference, number of items combined. Item2Vec simply use one item's embedding to find similar items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fef0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0dc9d9a-2921-462d-b2d4-3a00c1b57959",
   "metadata": {},
   "source": [
    "1. t-1 의 item 만 주고 추천\n",
    "2. 0~t-1 의 모든 item 들을 합하여 user vector 생성후 추천."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4423a-59a9-4533-8054-c71afa8b65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7517f-c1a3-4eee-823a-228fe5dc0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lookup embedding vector from item_id\n",
    "vec = item_vectors[806973001]\n",
    "\n",
    "# 2. Search nearest K-items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249201e-bef6-4d70-836d-8281764592d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bd2e5-c0ca-446c-951b-df9d198b4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in test_seq_df.iter_tuple():\n",
    "    row = getattr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd669919",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788bc34-e0e7-4754-9586-bd464a23d0fa",
   "metadata": {},
   "source": [
    "# Performance Metrics\n",
    "- Precision@K\n",
    "- Recall@K\n",
    "- NDCG@K\n",
    "- MAP@K\n",
    "- Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85367479-7ea1-4a52-89f3-a454e333be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_precision_recall(targets, predictions, k):\n",
    "    \"\"\"\n",
    "    targets : 실제 관심 있는 item list \n",
    "    predictions : prob sorted in descending order.\n",
    "    \"\"\"\n",
    "    pred = predictions[:k]\n",
    "    num_hit = len(set(pred).intersection(set(targets))) #  hit는 k개 추천 아이템 중에 사용자가 실제로 관심 있는 상품이 존재하는 경우를 의미하며, = TP\n",
    "    precision = float(num_hit) / len(pred)\n",
    "    recall = float(num_hit) / len(targets)\n",
    "    return precision, recall\n",
    "\n",
    "def ap(rel_items, recc_items, k=5):\n",
    "    precisions = []\n",
    "    for i in range(k):\n",
    "        k_recc = recc_items[:i+1]\n",
    "        n_hits = set(rel_items) & set(recc_items)\n",
    "        rel = recc_items[i] in rel_item #1/0\n",
    "        precisions.append(len(n_hits)/len(rel_items)*rel))\n",
    "    ap_k = sum(precisions) / len(precisions)\n",
    "    return ap_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e450b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f044da",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Item2Vec_tutorial_with_recsys_application](https://github.com/bwange/Item2vec_Tutorial_with_Recommender_System_Application/blob/master/Making_Your_Own_Recommender_System_with_Item2Vec.ipynb)\n",
    "2. [Word2Vec Tutorial Part I SkipGram - Chris McCormick](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model)\n",
    "3. [Word2Vec Tutorial Part II Negative Sampling - Chris McCormick](https://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)\n",
    "4. [Word2Vec to Recsys and Advertising - Chris McCormick](https://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.41px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
